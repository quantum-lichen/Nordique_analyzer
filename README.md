# ğŸ§  Nordique LMC

**Analyse Multi-IA par ComplexitÃ© Minimale (Least Model Complexity)**

Application Streamlit pour synthÃ©tiser et analyser le consensus entre multiples rÃ©ponses d'IA basÃ©e sur la thÃ©orie **CEML** (Cognitive Entropy Minimization Law).

---

## ğŸ¯ Qu'est-ce que c'est?

**Nordique LMC** permet d'analyser et de comparer les rÃ©ponses de plusieurs IA (Claude, ChatGPT, Gemini, etc.) pour identifier:

- âœ… **Consensus** - Ce sur quoi toutes les IA sont d'accord
- ğŸ”€ **Divergences** - Les perspectives uniques de chaque IA
- ğŸ’¡ **Insights** - Affirmations clÃ©s par IA
- âœ¨ **Ã‰mergences** - Concepts rares partagÃ©s entre 2 IA

---

## ğŸ”¬ ThÃ©orie: CEML

L'application utilise la thÃ©orie **CEML** (Cognitive Entropy Minimization Law):

```
J(s) = C(s|Î©) / (H(s) + Îµ)
```

OÃ¹:
- **J(s)** = Score LMC (Least Model Complexity)
- **C(s|Î©)** = CohÃ©rence contextuelle [0-1]
- **H(s)** = Entropie de Shannon [0-1]
- **Îµ** = Constante de rÃ©gularisation (dÃ©faut: 0.1)

**Plus le score est Ã©levÃ©, meilleure est la rÃ©ponse** (cohÃ©rente ET concise).

---

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8+
- pip

### Installation rapide

```bash
# Cloner le repo
git clone https://github.com/quantum-lichen/nordique-lmc.git
cd nordique-lmc

# Installer dÃ©pendances
pip install -r requirements.txt

# Lancer l'app
streamlit run app.py
```

L'app sera disponible Ã  `http://localhost:8501`

---

## ğŸ’» Utilisation

### 1. Configurer

Dans la barre latÃ©rale:
- Choisissez le nombre d'IA Ã  analyser (2-8)
- SÃ©lectionnez un prÃ©rÃ©glage ou ajustez manuellement:
  - **Îµ (epsilon)**: RÃ©gularisation
  - **Seuil similaritÃ©**: Pour consensus
  - **Longueur min**: Texte minimum Ã  analyser

### 2. Entrer les RÃ©ponses

Pour chaque IA:
- Nommez l'IA (Claude, ChatGPT, etc.)
- Collez la rÃ©ponse complÃ¨te
- Les scores (H, C, LMC) se calculent automatiquement

### 3. Analyser

Cliquez sur **"ğŸ” Analyser Consensus"** pour gÃ©nÃ©rer la synthÃ¨se multi-IA.

### 4. Explorer les RÃ©sultats

#### ğŸ¤ Consensus
- **Concepts partagÃ©s**: Mots clÃ©s prÃ©sents dans â‰¥50% des rÃ©ponses
- **Affirmations consensus**: Claims similaires entre IA (avec % confiance)

#### ğŸ”€ Divergences
- Concepts uniques Ã  chaque IA
- Score de divergence

#### ğŸ’¡ Insights
- CatÃ©gorisÃ©s par thÃ¨me:
  - Structure
  - Processus
  - Impact
  - Relation

#### âœ¨ Insights Ã‰mergents
- Concepts rares partagÃ©s entre exactement 2 IA
- Indique connexions non Ã©videntes

### 5. Exporter

- **JSON**: SynthÃ¨se complÃ¨te + rÃ©ponses
- **CSV**: Tableau des scores par IA

---

## ğŸ“Š PrÃ©rÃ©glages

| Preset | Îµ | Seuil | Longueur | Usage |
|--------|---|-------|----------|-------|
| **Standard** | 0.10 | 0.45 | 100 | Usage gÃ©nÃ©ral |
| **AcadÃ©mique** | 0.05 | 0.50 | 200 | Textes scientifiques |
| **CrÃ©atif** | 0.20 | 0.40 | 100 | Contenu crÃ©atif |
| **Strict** | 0.01 | 0.60 | 150 | Maximum rigueur |

---

## ğŸ—ï¸ Architecture

```
nordique-lmc/
â”œâ”€â”€ app.py                  # Application Streamlit principale
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ lmc_calculator.py   # Calculs LMC (H, C, score)
â”‚   â””â”€â”€ consensus_analyzer.py  # Analyse consensus/divergences
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ README.md              # Cette doc
â””â”€â”€ .gitignore
```

### Classes Principales

#### `LMCCalculator`
```python
from utils.lmc_calculator import LMCCalculator

lmc = LMCCalculator(epsilon=0.1)

# Calculer entropie
H = lmc.calculate_entropy(text)

# Calculer cohÃ©rence
C = lmc.calculate_coherence(text)

# Score LMC
score = lmc.calculate_lmc_score(text)

# Extraire affirmations
claims = lmc.extract_claims(text)
```

#### `ConsensusAnalyzer`
```python
from utils.consensus_analyzer import ConsensusAnalyzer, ResponseData

analyzer = ConsensusAnalyzer(similarity_threshold=0.45)

# PrÃ©parer rÃ©ponses
responses = {
    'ai_0': ResponseData(name='Claude', content='...', H=0.5, C=0.7, score=1.4),
    'ai_1': ResponseData(name='ChatGPT', content='...', H=0.4, C=0.8, score=2.0)
}

# Analyser
synthesis = analyzer.analyze_responses(responses)

# RÃ©sultats
consensus = synthesis['consensus']
divergences = synthesis['divergences']
insights = synthesis['insights']
emergent = synthesis['emergent_insights']
```

---

## ğŸ§ª Exemple d'Usage

```python
import streamlit as st
from utils.lmc_calculator import LMCCalculator
from utils.consensus_analyzer import ConsensusAnalyzer, ResponseData

# Init
lmc = LMCCalculator()
analyzer = ConsensusAnalyzer()

# RÃ©ponses
text1 = "Le miel aide Ã  calmer la toux..."
text2 = "Pour la toux, boire du thÃ© chaud..."

# Calculer scores
H1 = lmc.calculate_entropy(text1)
C1 = lmc.calculate_coherence(text1)
score1 = C1 / (H1 + 0.1)

responses = {
    'ai_0': ResponseData(name='IA1', content=text1, H=H1, C=C1, score=score1),
    'ai_1': ResponseData(name='IA2', content=text2, H=..., C=..., score=...)
}

# Analyser
synthesis = analyzer.analyze_responses(responses)

# Afficher
st.json(synthesis['consensus'])
```

---

## ğŸ“š ThÃ©orie CEML

### Entropie (H)

Mesure la **complexitÃ©** informationnelle du texte via l'entropie de Shannon:

```
H = -Î£ p(x) logâ‚‚ p(x)
```

- Plus l'entropie est Ã©levÃ©e, plus le texte est complexe/imprÃ©visible
- NormalisÃ©e Ã  [0-1]

### CohÃ©rence (C)

Mesure la **structure** du texte via plusieurs facteurs:

```
C = 0.25Â·repetition + 0.35Â·length + 0.30Â·content + 0.10Â·negation
```

- **RÃ©pÃ©tition**: Taux de mots rÃ©pÃ©tÃ©s (structure argumentative)
- **Longueur**: CohÃ©rence des phrases
- **Contenu**: Ratio mots de contenu vs stopwords
- **NÃ©gation**: Bonus pour complexitÃ© logique

### Score LMC

```
LMC = C / (H + Îµ)
```

**Principe**: Une bonne rÃ©ponse est **cohÃ©rente** (C Ã©levÃ©) mais **concise** (H bas).

**InterprÃ©tation**:
- `LMC < 1.0`: RÃ©ponse complexe/dÃ©cousue
- `LMC â‰ˆ 1.0-2.0`: RÃ©ponse Ã©quilibrÃ©e
- `LMC > 2.0`: RÃ©ponse trÃ¨s cohÃ©rente et concise (optimal)

---

## ğŸ”— Liens

- **Lichen Universe**: [GitHub](https://github.com/quantum-lichen/Lichen-Universe-Unified-V2)
- **ThÃ©orie CEML**: [Documentation](https://github.com/quantum-lichen/Lichen-Universe-Unified-V2/tree/main/CEML)
- **Manifest**: [manifest.json](https://quantum-lichen.github.io/Lichen-Universe-Unified-V2/manifest.json)

---

## ğŸ¤ Contribution

Les contributions sont bienvenues!

```bash
# Fork le repo
git clone https://github.com/ton-username/nordique-lmc.git

# CrÃ©er branche
git checkout -b feature/ma-fonctionnalite

# Commit
git commit -m "Ajout: ma fonctionnalitÃ©"

# Push
git push origin feature/ma-fonctionnalite

# CrÃ©er Pull Request
```

---

## ğŸ“œ License

Apache License 2.0 - Voir [LICENSE](LICENSE)

---

## ğŸ‘¤ Auteur

**Bryan Ouellette** ([Lichen Architect](https://github.com/quantum-lichen))

- Email: lmc.theory@gmail.com
- Bluesky: [@symbion.bsky.social](https://bsky.app/profile/symbion.bsky.social)

---

## ğŸ™ Remerciements

- **Claude AI** (Anthropic) - DÃ©veloppement & Recherche
- **ThÃ©orie CEML** - Foundation mathÃ©matique
- **Lichen Universe** - Ã‰cosystÃ¨me parent

---

## ğŸ“Š Statistiques

```python
{
  "version": "1.0.0",
  "language": "Python 3.8+",
  "framework": "Streamlit",
  "lines_of_code": "~1000",
  "classes": 3,
  "functions": 20+,
  "ai_supported": "8 max",
  "export_formats": ["JSON", "CSV"]
}
```

---

**ğŸ§  Nordique LMC - OÃ¹ la collaboration devient consensus**

ğŸ’š Fait avec amour pour l'IA Ã©thique et collaborative

---

## ğŸš€ DÃ©ploiement

### Streamlit Cloud

1. Push le repo sur GitHub
2. Va sur [streamlit.io/cloud](https://streamlit.io/cloud)
3. Connect ton repo
4. Deploy! âœ¨

### Heroku

```bash
# CrÃ©er app
heroku create nordique-lmc

# Deploy
git push heroku main

# Ouvrir
heroku open
```

### Docker

```bash
# Build
docker build -t nordique-lmc .

# Run
docker run -p 8501:8501 nordique-lmc
```

---

**Happy Analyzing! ğŸ‰**
